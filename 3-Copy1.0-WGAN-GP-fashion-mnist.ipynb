{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timsainb/tensorflow2-generative-models/blob/master/3.0-WGAN-GP-fashion-mnist.ipynb)\n",
    "\n",
    "## Wasserstein GAN with Gradient Penalty (WGAN-GP) ([article](https://arxiv.org/abs/1701.07875)) \n",
    "\n",
    "WGAN-GP is a GAN that improves over the original loss function to improve training stability. \n",
    "\n",
    "![wgan gp](imgs/gan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages if in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:26.962770Z",
     "start_time": "2019-05-14T06:38:26.957398Z"
    }
   },
   "outputs": [],
   "source": [
    "### install necessary packages if in colab\n",
    "def run_subprocess_command(cmd):\n",
    "  process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "  for line in process.stdout:\n",
    "      print(line.decode().strip())\n",
    "      \n",
    "import sys, subprocess\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "colab_requirements = ['pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190513']\n",
    "if IN_COLAB:\n",
    "  for i in colab_requirements:\n",
    "    run_subprocess_command(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:27.077677Z",
     "start_time": "2019-05-14T06:38:26.964728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# make visible the only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:31.202350Z",
     "start_time": "2019-05-14T06:38:27.080644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:31.213972Z",
     "start_time": "2019-05-14T06:38:31.207423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20190513\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:31.301144Z",
     "start_time": "2019-05-14T06:38:31.218082Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_BUF=60000\n",
    "BATCH_SIZE=512\n",
    "TEST_BUF=10000\n",
    "DIMS = (28,28,1)\n",
    "N_TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n",
    "N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:35.400311Z",
     "start_time": "2019-05-14T06:38:31.303121Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(train_images, _), (test_images, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# split dataset\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\n",
    "    \"float32\"\n",
    ") / 255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "# batch datasets\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    .shuffle(TRAIN_BUF)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(test_images)\n",
    "    .shuffle(TEST_BUF)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network as tf.keras.model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:35.423377Z",
     "start_time": "2019-05-14T06:38:35.402651Z"
    }
   },
   "outputs": [],
   "source": [
    "class WGAN(tf.keras.Model):\n",
    "    \"\"\"[summary]\n",
    "    I used github/LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2/ as a reference on this.\n",
    "    \n",
    "    Extends:\n",
    "        tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.gen = tf.keras.Sequential(self.gen)\n",
    "        self.disc = tf.keras.Sequential(self.disc)\n",
    "\n",
    "    def generate(self, z):\n",
    "        return self.gen(z)\n",
    "\n",
    "    def discriminate(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        ### pass through network\n",
    "        # generating noise from a uniform distribution\n",
    "\n",
    "        z_samp = tf.random.normal([x.shape[0], 1, 1, self.n_Z])\n",
    "\n",
    "        # run noise through generator\n",
    "        x_gen = self.generate(z_samp)\n",
    "        # discriminate x and x_gen\n",
    "        logits_x = self.discriminate(x)\n",
    "        logits_x_gen = self.discriminate(x_gen)\n",
    "\n",
    "        # gradient penalty\n",
    "        d_regularizer = self.gradient_penalty(x, x_gen)\n",
    "        ### losses\n",
    "        disc_loss = (\n",
    "            tf.reduce_mean(logits_x)\n",
    "            - tf.reduce_mean(logits_x_gen)\n",
    "            + d_regularizer * self.gradient_penalty_weight\n",
    "        )\n",
    "\n",
    "        # losses of fake with label \"1\"\n",
    "        gen_loss = tf.reduce_mean(logits_x_gen)\n",
    "\n",
    "        return disc_loss, gen_loss\n",
    "\n",
    "    def compute_gradients(self, x):\n",
    "        \"\"\" passes through the network and computes loss\n",
    "        \"\"\"\n",
    "        ### pass through network\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            disc_loss, gen_loss = self.compute_loss(x)\n",
    "\n",
    "        # compute gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, self.gen.trainable_variables)\n",
    "\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, self.disc.trainable_variables)\n",
    "\n",
    "        return gen_gradients, disc_gradients\n",
    "\n",
    "    def apply_gradients(self, gen_gradients, disc_gradients):\n",
    "\n",
    "        self.gen_optimizer.apply_gradients(\n",
    "            zip(gen_gradients, self.gen.trainable_variables)\n",
    "        )\n",
    "        self.disc_optimizer.apply_gradients(\n",
    "            zip(disc_gradients, self.disc.trainable_variables)\n",
    "        )\n",
    "\n",
    "    def gradient_penalty(self, x, x_gen):\n",
    "        epsilon = tf.random.uniform([x.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "        x_hat = epsilon * x + (1 - epsilon) * x_gen\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch(x_hat)\n",
    "            d_hat = self.discriminate(x_hat)\n",
    "        gradients = t.gradient(d_hat, x_hat)\n",
    "        ddx = tf.sqrt(tf.reduce_sum(gradients ** 2, axis=[1, 2]))\n",
    "        d_regularizer = tf.reduce_mean((ddx - 1.0) ** 2)\n",
    "        return d_regularizer\n",
    "\n",
    "    @tf.function\n",
    "    def train(self, train_x):\n",
    "        gen_gradients, disc_gradients = self.compute_gradients(train_x)\n",
    "        self.apply_gradients(gen_gradients, disc_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:35.552298Z",
     "start_time": "2019-05-14T06:38:35.425458Z"
    }
   },
   "outputs": [],
   "source": [
    "N_Z = 64\n",
    "\n",
    "generator = [\n",
    "    tf.keras.layers.Dense(units=7 * 7 * 64, activation=\"relu\"),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "discriminator = [\n",
    "    tf.keras.layers.InputLayer(input_shape=DIMS),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:40:40.306731Z",
     "start_time": "2019-05-10T18:40:40.292930Z"
    }
   },
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:36.413088Z",
     "start_time": "2019-05-14T06:38:35.554374Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizers\n",
    "gen_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.9)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.9)# train the model\n",
    "# model\n",
    "model = WGAN(\n",
    "    gen = generator,\n",
    "    disc = discriminator,\n",
    "    gen_optimizer = gen_optimizer,\n",
    "    disc_optimizer = disc_optimizer,\n",
    "    n_Z = N_Z,\n",
    "    gradient_penalty_weight = 10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:36.421755Z",
     "start_time": "2019-05-14T06:38:36.415263Z"
    }
   },
   "outputs": [],
   "source": [
    "# exampled data for plotting results\n",
    "def plot_reconstruction(model, nex=8, zm=2):\n",
    "    samples = model.generate(tf.random.normal(shape=(BATCH_SIZE, N_Z)))\n",
    "    fig, axs = plt.subplots(ncols=nex, nrows=1, figsize=(zm * nex, zm))\n",
    "    for axi in range(nex):\n",
    "        axs[axi].matshow(\n",
    "                    samples.numpy()[axi].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
    "                )\n",
    "        axs[axi].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:38:36.577118Z",
     "start_time": "2019-05-14T06:38:36.423655Z"
    }
   },
   "outputs": [],
   "source": [
    "# a pandas dataframe to save the loss information to\n",
    "losses = pd.DataFrame(columns = ['disc_loss', 'gen_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:47:21.977956Z",
     "start_time": "2019-05-14T06:38:36.579272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 | disc_loss: 0.2591356635093689 | gen_loss: 0.22652828693389893\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062e4ac0be6f4eaabd2447968a01508e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=117), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2dbc86e8cefb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_TRAIN_BATCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_TRAIN_BATCHES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ):\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# test on holdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    395\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \"\"\"\n\u001b[1;32m    565\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 566\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    567\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    568\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    420\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    421\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 422\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    for batch, train_x in tqdm(\n",
    "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
    "    ):\n",
    "        model.train(train_x)\n",
    "    # test on holdout\n",
    "    loss = []\n",
    "    for batch, test_x in tqdm(\n",
    "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\n",
    "    ):\n",
    "        loss.append(model.compute_loss(train_x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
    "    # plot results\n",
    "    display.clear_output()\n",
    "    print(\n",
    "        \"Epoch: {} | disc_loss: {} | gen_loss: {}\".format(\n",
    "            epoch, losses.disc_loss.values[-1], losses.gen_loss.values[-1]\n",
    "        )\n",
    "    )\n",
    "    plot_reconstruction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T06:47:21.982015Z",
     "start_time": "2019-05-14T06:38:26.535Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(losses.gen_loss.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
